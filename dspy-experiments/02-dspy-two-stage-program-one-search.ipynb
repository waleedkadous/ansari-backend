{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_vars import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This two-stage program answers Islam-related questions by leveraging a large language model and searching through authoritative Islamic sources. In the first stage, the program accepts a question, determines the language, and generates a relevant search query for Hadith, Quran, or the Encyclopedia of Islamic Jurisprudence (Mawsuah), if necessary. If a direct answer can be provided without searching, it is returned at this stage. Otherwise, the search query is executed, and relevant results are gathered. In the second stage, the original question, its language, and the search results are used to generate a factually based final answer. The answer is provided in the same language as the input question.\n",
    "\"\"\"\n",
    "\n",
    "import dspy\n",
    "from enum import Enum, auto\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchSource(str, Enum):\n",
    "    HADITH = \"Hadith\"\n",
    "    QURAN = \"Quran\"\n",
    "    MAWSUAH = \"Mawsuah\"\n",
    "    NONE = \"None\"\n",
    "\n",
    "class Stage1InputQuery(BaseModel):\n",
    "    query: str = Field(description=\"Islam-related question\")\n",
    "\n",
    "class Stage1OutputResult(BaseModel):\n",
    "    language: str = Field(description=\"Language of the question\")\n",
    "    search_source: SearchSource = Field(description=\"Indicates the source for search: Hadith, Quran, Mawsuah, or None\")\n",
    "    search_query: str = Field(description=\"Query for the specified search source in Arabic\")\n",
    "    direct_answer: str = Field(description=\"Direct answer to the question in the same language as the question, if no search is required\")\n",
    "\n",
    "class GenerateStage1Output(dspy.Signature):\n",
    "    \"\"\"Formulate a search query for an Islamic source only when a direct answer is not possible, based on a given question, to optimize the retrieval of relevant search results.\n",
    "\n",
    "    Accept an Islam-related question, which may not be in Arabic, and determine the appropriate source (Hadith, Quran, or Mawsuah) for the search query in the Arabic language. The goal is to maximize the likelihood of obtaining pertinent search results by conducting a search only when a direct answer cannot be provided without it.\n",
    "    \"\"\"\n",
    "    input: Stage1InputQuery = dspy.InputField()\n",
    "    output: Stage1OutputResult = dspy.OutputField()\n",
    "\n",
    "class Stage2InputData(BaseModel):\n",
    "    question: str = Field(description=\"An Islam-related question\")\n",
    "    language: str = Field(description=\"Language of the question\")\n",
    "    searched_source: SearchSource = Field(description=\"The source that was searched: Hadith, Quran, or Mawsuah\")\n",
    "    search_results: list[str] = Field(description=\"List of search results that might be relevant to the question\")\n",
    "\n",
    "class Stage2OutputAnswer(BaseModel):\n",
    "    answer: str = Field(description=\"Final answer to the question in the same language as the question, based on the relevant search results from Hadith, Quran, or Mawsuah\")\n",
    "\n",
    "class GenerateStage2FinalAnswer(dspy.Signature):\n",
    "    \"\"\"Produce a factually based final answer to an Islam-related question using search results.\n",
    "\n",
    "    Accept an input containing the original question, its language, the searched source, and the search results. Return the final answer to the question, synthesized from the provided search results and articulated in the same language as the input question.\n",
    "    \"\"\"\n",
    "    input: Stage2InputData = dspy.InputField()\n",
    "    output: Stage2OutputAnswer = dspy.OutputField()\n",
    "\n",
    "stage1_predictor = dspy.TypedPredictor(GenerateStage1Output, max_retries=5, explain_errors=True)\n",
    "stage2_predictor = dspy.TypedPredictor(GenerateStage2FinalAnswer, max_retries=5, explain_errors=True)\n",
    "\n",
    "from tools.search_hadith import SearchHadith\n",
    "from tools.search_quran import SearchQuran\n",
    "from tools.search_mawsuah import SearchMawsuah\n",
    "\n",
    "llm_gpt4 = dspy.OpenAI(model='gpt-4-turbo-2024-04-09', api_key=openai_key)\n",
    "llm_gpt3 = dspy.OpenAI(model='gpt-3.5-turbo-0125', api_key=openai_key)\n",
    "ms = SearchMawsuah(auth_token=VECTARA_AUTH_TOKEN, customer_id=VECTARA_CUSTOMER_ID, corpus_id=VECTARA_CORPUS_ID)\n",
    "hs = SearchHadith(api_key=kalimat_api_key)\n",
    "qs = SearchQuran(api_key=kalimat_api_key)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def process_question(question: str):\n",
    "    # Stage 1: Generate search query or provide a direct answer\n",
    "    with dspy.context(lm=llm_gpt4):\n",
    "        stage1_input = Stage1InputQuery(query=question)\n",
    "        stage1_prediction = stage1_predictor(input=stage1_input)\n",
    "        pprint(stage1_prediction.output.dict())\n",
    "\n",
    "    if stage1_prediction.output.direct_answer.strip():\n",
    "        return stage1_prediction.output.direct_answer\n",
    "\n",
    "    search_source = stage1_prediction.output.search_source\n",
    "    search_query = stage1_prediction.output.search_query\n",
    "\n",
    "    # Stage 1 search query results\n",
    "    search_results = []\n",
    "    if search_source == SearchSource.HADITH:\n",
    "        search_results = hs.run_as_list(search_query)\n",
    "        pprint(search_results)\n",
    "    elif search_source == SearchSource.QURAN:\n",
    "        search_results = qs.run_as_list(search_query)\n",
    "        pprint(search_results)\n",
    "    elif search_source == SearchSource.MAWSUAH:\n",
    "        search_results = ms.run_as_list(search_query)\n",
    "        pprint(search_results)\n",
    "\n",
    "    # Stage 2: Generate the final answer using search results\n",
    "    with dspy.context(lm=llm_gpt4):\n",
    "        stage2_input = Stage2InputData(question=question, language=stage1_prediction.output.language, searched_source=search_source, search_results=search_results)\n",
    "        stage2_prediction = stage2_predictor(input=stage2_input)\n",
    "        pprint(stage2_prediction.output.dict())\n",
    "    return stage2_prediction.output.answer\n",
    "\n",
    "question = \"kadinlarin basortusu takmalari sart mi?\"\n",
    "final_answer = process_question(question)\n",
    "pprint(final_answer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
